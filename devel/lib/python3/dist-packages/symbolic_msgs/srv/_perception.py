# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from symbolic_msgs/perceptionRequest.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct


class perceptionRequest(genpy.Message):
  _md5sum = "a56b4c511424086489b1c3d34bfcfd4f"
  _type = "symbolic_msgs/perceptionRequest"
  _has_header = False  # flag to mark the presence of a Header object
  _full_text = """# request
bool detect_obj
int32 place
"""
  __slots__ = ['detect_obj','place']
  _slot_types = ['bool','int32']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       detect_obj,place

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(perceptionRequest, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.detect_obj is None:
        self.detect_obj = False
      if self.place is None:
        self.place = 0
    else:
      self.detect_obj = False
      self.place = 0

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_get_struct_Bi().pack(_x.detect_obj, _x.place))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      end = 0
      _x = self
      start = end
      end += 5
      (_x.detect_obj, _x.place,) = _get_struct_Bi().unpack(str[start:end])
      self.detect_obj = bool(self.detect_obj)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_get_struct_Bi().pack(_x.detect_obj, _x.place))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      end = 0
      _x = self
      start = end
      end += 5
      (_x.detect_obj, _x.place,) = _get_struct_Bi().unpack(str[start:end])
      self.detect_obj = bool(self.detect_obj)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_Bi = None
def _get_struct_Bi():
    global _struct_Bi
    if _struct_Bi is None:
        _struct_Bi = struct.Struct("<Bi")
    return _struct_Bi
# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from symbolic_msgs/perceptionResponse.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import geometry_msgs.msg
import sensor_msgs.msg
import std_msgs.msg
import vision_msgs.msg

class perceptionResponse(genpy.Message):
  _md5sum = "a0b9e0274823afa5f617b0cb4bacf180"
  _type = "symbolic_msgs/perceptionResponse"
  _has_header = False  # flag to mark the presence of a Header object
  _full_text = """# rosponse
bool success
vision_msgs/Detection2DArray det_2d
std_msgs/Int16MultiArray instance_id
vision_msgs/Detection3DArray det_3d
geometry_msgs/PoseArray grasp_pose
vision_msgs/BoundingBox3D table_pose
vision_msgs/BoundingBox3D shelf_pose

================================================================================
MSG: vision_msgs/Detection2DArray
# A list of 2D detections, for a multi-object 2D detector.

Header header

# A list of the detected proposals. A multi-proposal detector might generate
#   this list with many candidate detections generated from a single input.
Detection2D[] detections

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')
# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
string frame_id

================================================================================
MSG: vision_msgs/Detection2D
# Defines a 2D detection result.
#
# This is similar to a 2D classification, but includes position information,
#   allowing a classification result for a specific crop or image point to
#   to be located in the larger image.

Header header

# Class probabilities
ObjectHypothesisWithPose[] results

# 2D bounding box surrounding the object.
BoundingBox2D bbox

# The 2D data that generated these results (i.e. region proposal cropped out of
#   the image). Not required for all use cases, so it may be empty.
sensor_msgs/Image source_img

================================================================================
MSG: vision_msgs/ObjectHypothesisWithPose
# An object hypothesis that contains position information.

# The unique numeric ID of object detected. To get additional information about
#   this ID, such as its human-readable name, listeners should perform a lookup
#   in a metadata database. See vision_msgs/VisionInfo.msg for more detail.
int64 id

# The probability or confidence value of the detected object. By convention,
#   this value should lie in the range [0-1].
float64 score

# The 6D pose of the object hypothesis. This pose should be
#   defined as the pose of some fixed reference point on the object, such a
#   the geometric center of the bounding box or the center of mass of the
#   object.
# Note that this pose is not stamped; frame information can be defined by
#   parent messages.
# Also note that different classes predicted for the same input data may have
#   different predicted 6D poses.
geometry_msgs/PoseWithCovariance pose
================================================================================
MSG: geometry_msgs/PoseWithCovariance
# This represents a pose in free space with uncertainty.

Pose pose

# Row-major representation of the 6x6 covariance matrix
# The orientation parameters use a fixed-axis representation.
# In order, the parameters are:
# (x, y, z, rotation about X axis, rotation about Y axis, rotation about Z axis)
float64[36] covariance

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of position and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w

================================================================================
MSG: vision_msgs/BoundingBox2D
# A 2D bounding box that can be rotated about its center.
# All dimensions are in pixels, but represented using floating-point
#   values to allow sub-pixel precision. If an exact pixel crop is required
#   for a rotated bounding box, it can be calculated using Bresenham's line
#   algorithm.

# The 2D position (in pixels) and orientation of the bounding box center.
geometry_msgs/Pose2D center

# The size (in pixels) of the bounding box surrounding the object relative
#   to the pose of its center.
float64 size_x
float64 size_y

================================================================================
MSG: geometry_msgs/Pose2D
# Deprecated
# Please use the full 3D pose.

# In general our recommendation is to use a full 3D representation of everything and for 2D specific applications make the appropriate projections into the plane for their calculations but optimally will preserve the 3D information during processing.

# If we have parallel copies of 2D datatypes every UI and other pipeline will end up needing to have dual interfaces to plot everything. And you will end up with not being able to use 3D tools for 2D use cases even if they're completely valid, as you'd have to reimplement it with different inputs and outputs. It's not particularly hard to plot the 2D pose or compute the yaw error for the Pose message and there are already tools and libraries that can do this for you.


# This expresses a position and orientation on a 2D manifold.

float64 x
float64 y
float64 theta

================================================================================
MSG: sensor_msgs/Image
# This message contains an uncompressed image
# (0, 0) is at top-left corner of image
#

Header header        # Header timestamp should be acquisition time of image
                     # Header frame_id should be optical frame of camera
                     # origin of frame should be optical center of camera
                     # +x should point to the right in the image
                     # +y should point down in the image
                     # +z should point into to plane of the image
                     # If the frame_id here and the frame_id of the CameraInfo
                     # message associated with the image conflict
                     # the behavior is undefined

uint32 height         # image height, that is, number of rows
uint32 width          # image width, that is, number of columns

# The legal values for encoding are in file src/image_encodings.cpp
# If you want to standardize a new string format, join
# ros-users@lists.sourceforge.net and send an email proposing a new encoding.

string encoding       # Encoding of pixels -- channel meaning, ordering, size
                      # taken from the list of strings in include/sensor_msgs/image_encodings.h

uint8 is_bigendian    # is this data bigendian?
uint32 step           # Full row length in bytes
uint8[] data          # actual matrix data, size is (step * rows)

================================================================================
MSG: std_msgs/Int16MultiArray
# Please look at the MultiArrayLayout message definition for
# documentation on all multiarrays.

MultiArrayLayout  layout        # specification of data layout
int16[]           data          # array of data


================================================================================
MSG: std_msgs/MultiArrayLayout
# The multiarray declares a generic multi-dimensional array of a
# particular data type.  Dimensions are ordered from outer most
# to inner most.

MultiArrayDimension[] dim # Array of dimension properties
uint32 data_offset        # padding elements at front of data

# Accessors should ALWAYS be written in terms of dimension stride
# and specified outer-most dimension first.
# 
# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]
#
# A standard, 3-channel 640x480 image with interleaved color channels
# would be specified as:
#
# dim[0].label  = "height"
# dim[0].size   = 480
# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)
# dim[1].label  = "width"
# dim[1].size   = 640
# dim[1].stride = 3*640 = 1920
# dim[2].label  = "channel"
# dim[2].size   = 3
# dim[2].stride = 3
#
# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.

================================================================================
MSG: std_msgs/MultiArrayDimension
string label   # label of given dimension
uint32 size    # size of given dimension (in type units)
uint32 stride  # stride of given dimension
================================================================================
MSG: vision_msgs/Detection3DArray
# A list of 3D detections, for a multi-object 3D detector.

Header header

# A list of the detected proposals. A multi-proposal detector might generate
#   this list with many candidate detections generated from a single input.
Detection3D[] detections

================================================================================
MSG: vision_msgs/Detection3D
# Defines a 3D detection result.
#
# This extends a basic 3D classification by including position information,
#   allowing a classification result for a specific position in an image to
#   to be located in the larger image.

Header header

# Class probabilities. Does not have to include hypotheses for all possible
#   object ids, the scores for any ids not listed are assumed to be 0.
ObjectHypothesisWithPose[] results

# 3D bounding box surrounding the object.
BoundingBox3D bbox

# The 3D data that generated these results (i.e. region proposal cropped out of
#   the image). This information is not required for all detectors, so it may
#   be empty.
sensor_msgs/PointCloud2 source_cloud

================================================================================
MSG: vision_msgs/BoundingBox3D
# A 3D bounding box that can be positioned and rotated about its center (6 DOF)
# Dimensions of this box are in meters, and as such, it may be migrated to
#   another package, such as geometry_msgs, in the future.

# The 3D position and orientation of the bounding box center
geometry_msgs/Pose center

# The size of the bounding box, in meters, surrounding the object's center
#   pose.
geometry_msgs/Vector3 size

================================================================================
MSG: geometry_msgs/Vector3
# This represents a vector in free space. 
# It is only meant to represent a direction. Therefore, it does not
# make sense to apply a translation to it (e.g., when applying a 
# generic rigid transformation to a Vector3, tf2 will only apply the
# rotation). If you want your data to be translatable too, use the
# geometry_msgs/Point message instead.

float64 x
float64 y
float64 z
================================================================================
MSG: sensor_msgs/PointCloud2
# This message holds a collection of N-dimensional points, which may
# contain additional information such as normals, intensity, etc. The
# point data is stored as a binary blob, its layout described by the
# contents of the "fields" array.

# The point cloud data may be organized 2d (image-like) or 1d
# (unordered). Point clouds organized as 2d images may be produced by
# camera depth sensors such as stereo or time-of-flight.

# Time of sensor data acquisition, and the coordinate frame ID (for 3d
# points).
Header header

# 2D structure of the point cloud. If the cloud is unordered, height is
# 1 and width is the length of the point cloud.
uint32 height
uint32 width

# Describes the channels and their layout in the binary data blob.
PointField[] fields

bool    is_bigendian # Is this data bigendian?
uint32  point_step   # Length of a point in bytes
uint32  row_step     # Length of a row in bytes
uint8[] data         # Actual point data, size is (row_step*height)

bool is_dense        # True if there are no invalid points

================================================================================
MSG: sensor_msgs/PointField
# This message holds the description of one point entry in the
# PointCloud2 message format.
uint8 INT8    = 1
uint8 UINT8   = 2
uint8 INT16   = 3
uint8 UINT16  = 4
uint8 INT32   = 5
uint8 UINT32  = 6
uint8 FLOAT32 = 7
uint8 FLOAT64 = 8

string name      # Name of field
uint32 offset    # Offset from start of point struct
uint8  datatype  # Datatype enumeration, see above
uint32 count     # How many elements in the field

================================================================================
MSG: geometry_msgs/PoseArray
# An array of poses with a header for global reference.

Header header

Pose[] poses
"""
  __slots__ = ['success','det_2d','instance_id','det_3d','grasp_pose','table_pose','shelf_pose']
  _slot_types = ['bool','vision_msgs/Detection2DArray','std_msgs/Int16MultiArray','vision_msgs/Detection3DArray','geometry_msgs/PoseArray','vision_msgs/BoundingBox3D','vision_msgs/BoundingBox3D']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       success,det_2d,instance_id,det_3d,grasp_pose,table_pose,shelf_pose

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(perceptionResponse, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.success is None:
        self.success = False
      if self.det_2d is None:
        self.det_2d = vision_msgs.msg.Detection2DArray()
      if self.instance_id is None:
        self.instance_id = std_msgs.msg.Int16MultiArray()
      if self.det_3d is None:
        self.det_3d = vision_msgs.msg.Detection3DArray()
      if self.grasp_pose is None:
        self.grasp_pose = geometry_msgs.msg.PoseArray()
      if self.table_pose is None:
        self.table_pose = vision_msgs.msg.BoundingBox3D()
      if self.shelf_pose is None:
        self.shelf_pose = vision_msgs.msg.BoundingBox3D()
    else:
      self.success = False
      self.det_2d = vision_msgs.msg.Detection2DArray()
      self.instance_id = std_msgs.msg.Int16MultiArray()
      self.det_3d = vision_msgs.msg.Detection3DArray()
      self.grasp_pose = geometry_msgs.msg.PoseArray()
      self.table_pose = vision_msgs.msg.BoundingBox3D()
      self.shelf_pose = vision_msgs.msg.BoundingBox3D()

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_get_struct_B3I().pack(_x.success, _x.det_2d.header.seq, _x.det_2d.header.stamp.secs, _x.det_2d.header.stamp.nsecs))
      _x = self.det_2d.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.det_2d.detections)
      buff.write(_struct_I.pack(length))
      for val1 in self.det_2d.detections:
        _v1 = val1.header
        _x = _v1.seq
        buff.write(_get_struct_I().pack(_x))
        _v2 = _v1.stamp
        _x = _v2
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v1.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        length = len(val1.results)
        buff.write(_struct_I.pack(length))
        for val2 in val1.results:
          _x = val2
          buff.write(_get_struct_qd().pack(_x.id, _x.score))
          _v3 = val2.pose
          _v4 = _v3.pose
          _v5 = _v4.position
          _x = _v5
          buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
          _v6 = _v4.orientation
          _x = _v6
          buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_get_struct_36d().pack(*_v3.covariance))
        _v7 = val1.bbox
        _v8 = _v7.center
        _x = _v8
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.theta))
        _x = _v7
        buff.write(_get_struct_2d().pack(_x.size_x, _x.size_y))
        _v9 = val1.source_img
        _v10 = _v9.header
        _x = _v10.seq
        buff.write(_get_struct_I().pack(_x))
        _v11 = _v10.stamp
        _x = _v11
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v10.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v9
        buff.write(_get_struct_2I().pack(_x.height, _x.width))
        _x = _v9.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v9
        buff.write(_get_struct_BI().pack(_x.is_bigendian, _x.step))
        _x = _v9.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
        else:
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.instance_id.layout.dim)
      buff.write(_struct_I.pack(length))
      for val1 in self.instance_id.layout.dim:
        _x = val1.label
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = val1
        buff.write(_get_struct_2I().pack(_x.size, _x.stride))
      _x = self.instance_id.layout.data_offset
      buff.write(_get_struct_I().pack(_x))
      length = len(self.instance_id.data)
      buff.write(_struct_I.pack(length))
      pattern = '<%sh'%length
      buff.write(struct.Struct(pattern).pack(*self.instance_id.data))
      _x = self
      buff.write(_get_struct_3I().pack(_x.det_3d.header.seq, _x.det_3d.header.stamp.secs, _x.det_3d.header.stamp.nsecs))
      _x = self.det_3d.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.det_3d.detections)
      buff.write(_struct_I.pack(length))
      for val1 in self.det_3d.detections:
        _v12 = val1.header
        _x = _v12.seq
        buff.write(_get_struct_I().pack(_x))
        _v13 = _v12.stamp
        _x = _v13
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v12.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        length = len(val1.results)
        buff.write(_struct_I.pack(length))
        for val2 in val1.results:
          _x = val2
          buff.write(_get_struct_qd().pack(_x.id, _x.score))
          _v14 = val2.pose
          _v15 = _v14.pose
          _v16 = _v15.position
          _x = _v16
          buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
          _v17 = _v15.orientation
          _x = _v17
          buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_get_struct_36d().pack(*_v14.covariance))
        _v18 = val1.bbox
        _v19 = _v18.center
        _v20 = _v19.position
        _x = _v20
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v21 = _v19.orientation
        _x = _v21
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        _v22 = _v18.size
        _x = _v22
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v23 = val1.source_cloud
        _v24 = _v23.header
        _x = _v24.seq
        buff.write(_get_struct_I().pack(_x))
        _v25 = _v24.stamp
        _x = _v25
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v24.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v23
        buff.write(_get_struct_2I().pack(_x.height, _x.width))
        length = len(_v23.fields)
        buff.write(_struct_I.pack(length))
        for val3 in _v23.fields:
          _x = val3.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
          _x = val3
          buff.write(_get_struct_IBI().pack(_x.offset, _x.datatype, _x.count))
        _x = _v23
        buff.write(_get_struct_B2I().pack(_x.is_bigendian, _x.point_step, _x.row_step))
        _x = _v23.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
        else:
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v23.is_dense
        buff.write(_get_struct_B().pack(_x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.grasp_pose.header.seq, _x.grasp_pose.header.stamp.secs, _x.grasp_pose.header.stamp.nsecs))
      _x = self.grasp_pose.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.grasp_pose.poses)
      buff.write(_struct_I.pack(length))
      for val1 in self.grasp_pose.poses:
        _v26 = val1.position
        _x = _v26
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v27 = val1.orientation
        _x = _v27
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
      _x = self
      buff.write(_get_struct_20d().pack(_x.table_pose.center.position.x, _x.table_pose.center.position.y, _x.table_pose.center.position.z, _x.table_pose.center.orientation.x, _x.table_pose.center.orientation.y, _x.table_pose.center.orientation.z, _x.table_pose.center.orientation.w, _x.table_pose.size.x, _x.table_pose.size.y, _x.table_pose.size.z, _x.shelf_pose.center.position.x, _x.shelf_pose.center.position.y, _x.shelf_pose.center.position.z, _x.shelf_pose.center.orientation.x, _x.shelf_pose.center.orientation.y, _x.shelf_pose.center.orientation.z, _x.shelf_pose.center.orientation.w, _x.shelf_pose.size.x, _x.shelf_pose.size.y, _x.shelf_pose.size.z))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.det_2d is None:
        self.det_2d = vision_msgs.msg.Detection2DArray()
      if self.instance_id is None:
        self.instance_id = std_msgs.msg.Int16MultiArray()
      if self.det_3d is None:
        self.det_3d = vision_msgs.msg.Detection3DArray()
      if self.grasp_pose is None:
        self.grasp_pose = geometry_msgs.msg.PoseArray()
      if self.table_pose is None:
        self.table_pose = vision_msgs.msg.BoundingBox3D()
      if self.shelf_pose is None:
        self.shelf_pose = vision_msgs.msg.BoundingBox3D()
      end = 0
      _x = self
      start = end
      end += 13
      (_x.success, _x.det_2d.header.seq, _x.det_2d.header.stamp.secs, _x.det_2d.header.stamp.nsecs,) = _get_struct_B3I().unpack(str[start:end])
      self.success = bool(self.success)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.det_2d.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.det_2d.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.det_2d.detections = []
      for i in range(0, length):
        val1 = vision_msgs.msg.Detection2D()
        _v28 = val1.header
        start = end
        end += 4
        (_v28.seq,) = _get_struct_I().unpack(str[start:end])
        _v29 = _v28.stamp
        _x = _v29
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v28.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v28.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.results = []
        for i in range(0, length):
          val2 = vision_msgs.msg.ObjectHypothesisWithPose()
          _x = val2
          start = end
          end += 16
          (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
          _v30 = val2.pose
          _v31 = _v30.pose
          _v32 = _v31.position
          _x = _v32
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
          _v33 = _v31.orientation
          _x = _v33
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
          start = end
          end += 288
          _v30.covariance = _get_struct_36d().unpack(str[start:end])
          val1.results.append(val2)
        _v34 = val1.bbox
        _v35 = _v34.center
        _x = _v35
        start = end
        end += 24
        (_x.x, _x.y, _x.theta,) = _get_struct_3d().unpack(str[start:end])
        _x = _v34
        start = end
        end += 16
        (_x.size_x, _x.size_y,) = _get_struct_2d().unpack(str[start:end])
        _v36 = val1.source_img
        _v37 = _v36.header
        start = end
        end += 4
        (_v37.seq,) = _get_struct_I().unpack(str[start:end])
        _v38 = _v37.stamp
        _x = _v38
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v37.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v37.frame_id = str[start:end]
        _x = _v36
        start = end
        end += 8
        (_x.height, _x.width,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v36.encoding = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v36.encoding = str[start:end]
        _x = _v36
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _get_struct_BI().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        _v36.data = str[start:end]
        self.det_2d.detections.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.instance_id.layout.dim = []
      for i in range(0, length):
        val1 = std_msgs.msg.MultiArrayDimension()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.label = str[start:end].decode('utf-8', 'rosmsg')
        else:
          val1.label = str[start:end]
        _x = val1
        start = end
        end += 8
        (_x.size, _x.stride,) = _get_struct_2I().unpack(str[start:end])
        self.instance_id.layout.dim.append(val1)
      start = end
      end += 4
      (self.instance_id.layout.data_offset,) = _get_struct_I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sh'%length
      start = end
      s = struct.Struct(pattern)
      end += s.size
      self.instance_id.data = s.unpack(str[start:end])
      _x = self
      start = end
      end += 12
      (_x.det_3d.header.seq, _x.det_3d.header.stamp.secs, _x.det_3d.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.det_3d.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.det_3d.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.det_3d.detections = []
      for i in range(0, length):
        val1 = vision_msgs.msg.Detection3D()
        _v39 = val1.header
        start = end
        end += 4
        (_v39.seq,) = _get_struct_I().unpack(str[start:end])
        _v40 = _v39.stamp
        _x = _v40
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v39.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v39.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.results = []
        for i in range(0, length):
          val2 = vision_msgs.msg.ObjectHypothesisWithPose()
          _x = val2
          start = end
          end += 16
          (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
          _v41 = val2.pose
          _v42 = _v41.pose
          _v43 = _v42.position
          _x = _v43
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
          _v44 = _v42.orientation
          _x = _v44
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
          start = end
          end += 288
          _v41.covariance = _get_struct_36d().unpack(str[start:end])
          val1.results.append(val2)
        _v45 = val1.bbox
        _v46 = _v45.center
        _v47 = _v46.position
        _x = _v47
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v48 = _v46.orientation
        _x = _v48
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        _v49 = _v45.size
        _x = _v49
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v50 = val1.source_cloud
        _v51 = _v50.header
        start = end
        end += 4
        (_v51.seq,) = _get_struct_I().unpack(str[start:end])
        _v52 = _v51.stamp
        _x = _v52
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v51.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v51.frame_id = str[start:end]
        _x = _v50
        start = end
        end += 8
        (_x.height, _x.width,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v50.fields = []
        for i in range(0, length):
          val3 = sensor_msgs.msg.PointField()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val3.name = str[start:end].decode('utf-8', 'rosmsg')
          else:
            val3.name = str[start:end]
          _x = val3
          start = end
          end += 9
          (_x.offset, _x.datatype, _x.count,) = _get_struct_IBI().unpack(str[start:end])
          _v50.fields.append(val3)
        _x = _v50
        start = end
        end += 9
        (_x.is_bigendian, _x.point_step, _x.row_step,) = _get_struct_B2I().unpack(str[start:end])
        _v50.is_bigendian = bool(_v50.is_bigendian)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        _v50.data = str[start:end]
        start = end
        end += 1
        (_v50.is_dense,) = _get_struct_B().unpack(str[start:end])
        _v50.is_dense = bool(_v50.is_dense)
        self.det_3d.detections.append(val1)
      _x = self
      start = end
      end += 12
      (_x.grasp_pose.header.seq, _x.grasp_pose.header.stamp.secs, _x.grasp_pose.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.grasp_pose.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.grasp_pose.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.grasp_pose.poses = []
      for i in range(0, length):
        val1 = geometry_msgs.msg.Pose()
        _v53 = val1.position
        _x = _v53
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v54 = val1.orientation
        _x = _v54
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        self.grasp_pose.poses.append(val1)
      _x = self
      start = end
      end += 160
      (_x.table_pose.center.position.x, _x.table_pose.center.position.y, _x.table_pose.center.position.z, _x.table_pose.center.orientation.x, _x.table_pose.center.orientation.y, _x.table_pose.center.orientation.z, _x.table_pose.center.orientation.w, _x.table_pose.size.x, _x.table_pose.size.y, _x.table_pose.size.z, _x.shelf_pose.center.position.x, _x.shelf_pose.center.position.y, _x.shelf_pose.center.position.z, _x.shelf_pose.center.orientation.x, _x.shelf_pose.center.orientation.y, _x.shelf_pose.center.orientation.z, _x.shelf_pose.center.orientation.w, _x.shelf_pose.size.x, _x.shelf_pose.size.y, _x.shelf_pose.size.z,) = _get_struct_20d().unpack(str[start:end])
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_get_struct_B3I().pack(_x.success, _x.det_2d.header.seq, _x.det_2d.header.stamp.secs, _x.det_2d.header.stamp.nsecs))
      _x = self.det_2d.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.det_2d.detections)
      buff.write(_struct_I.pack(length))
      for val1 in self.det_2d.detections:
        _v55 = val1.header
        _x = _v55.seq
        buff.write(_get_struct_I().pack(_x))
        _v56 = _v55.stamp
        _x = _v56
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v55.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        length = len(val1.results)
        buff.write(_struct_I.pack(length))
        for val2 in val1.results:
          _x = val2
          buff.write(_get_struct_qd().pack(_x.id, _x.score))
          _v57 = val2.pose
          _v58 = _v57.pose
          _v59 = _v58.position
          _x = _v59
          buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
          _v60 = _v58.orientation
          _x = _v60
          buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_v57.covariance.tostring())
        _v61 = val1.bbox
        _v62 = _v61.center
        _x = _v62
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.theta))
        _x = _v61
        buff.write(_get_struct_2d().pack(_x.size_x, _x.size_y))
        _v63 = val1.source_img
        _v64 = _v63.header
        _x = _v64.seq
        buff.write(_get_struct_I().pack(_x))
        _v65 = _v64.stamp
        _x = _v65
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v64.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v63
        buff.write(_get_struct_2I().pack(_x.height, _x.width))
        _x = _v63.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v63
        buff.write(_get_struct_BI().pack(_x.is_bigendian, _x.step))
        _x = _v63.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
        else:
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.instance_id.layout.dim)
      buff.write(_struct_I.pack(length))
      for val1 in self.instance_id.layout.dim:
        _x = val1.label
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = val1
        buff.write(_get_struct_2I().pack(_x.size, _x.stride))
      _x = self.instance_id.layout.data_offset
      buff.write(_get_struct_I().pack(_x))
      length = len(self.instance_id.data)
      buff.write(_struct_I.pack(length))
      pattern = '<%sh'%length
      buff.write(self.instance_id.data.tostring())
      _x = self
      buff.write(_get_struct_3I().pack(_x.det_3d.header.seq, _x.det_3d.header.stamp.secs, _x.det_3d.header.stamp.nsecs))
      _x = self.det_3d.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.det_3d.detections)
      buff.write(_struct_I.pack(length))
      for val1 in self.det_3d.detections:
        _v66 = val1.header
        _x = _v66.seq
        buff.write(_get_struct_I().pack(_x))
        _v67 = _v66.stamp
        _x = _v67
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v66.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        length = len(val1.results)
        buff.write(_struct_I.pack(length))
        for val2 in val1.results:
          _x = val2
          buff.write(_get_struct_qd().pack(_x.id, _x.score))
          _v68 = val2.pose
          _v69 = _v68.pose
          _v70 = _v69.position
          _x = _v70
          buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
          _v71 = _v69.orientation
          _x = _v71
          buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_v68.covariance.tostring())
        _v72 = val1.bbox
        _v73 = _v72.center
        _v74 = _v73.position
        _x = _v74
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v75 = _v73.orientation
        _x = _v75
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        _v76 = _v72.size
        _x = _v76
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v77 = val1.source_cloud
        _v78 = _v77.header
        _x = _v78.seq
        buff.write(_get_struct_I().pack(_x))
        _v79 = _v78.stamp
        _x = _v79
        buff.write(_get_struct_2I().pack(_x.secs, _x.nsecs))
        _x = _v78.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v77
        buff.write(_get_struct_2I().pack(_x.height, _x.width))
        length = len(_v77.fields)
        buff.write(_struct_I.pack(length))
        for val3 in _v77.fields:
          _x = val3.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
          _x = val3
          buff.write(_get_struct_IBI().pack(_x.offset, _x.datatype, _x.count))
        _x = _v77
        buff.write(_get_struct_B2I().pack(_x.is_bigendian, _x.point_step, _x.row_step))
        _x = _v77.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
        else:
          buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
        _x = _v77.is_dense
        buff.write(_get_struct_B().pack(_x))
      _x = self
      buff.write(_get_struct_3I().pack(_x.grasp_pose.header.seq, _x.grasp_pose.header.stamp.secs, _x.grasp_pose.header.stamp.nsecs))
      _x = self.grasp_pose.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.grasp_pose.poses)
      buff.write(_struct_I.pack(length))
      for val1 in self.grasp_pose.poses:
        _v80 = val1.position
        _x = _v80
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v81 = val1.orientation
        _x = _v81
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
      _x = self
      buff.write(_get_struct_20d().pack(_x.table_pose.center.position.x, _x.table_pose.center.position.y, _x.table_pose.center.position.z, _x.table_pose.center.orientation.x, _x.table_pose.center.orientation.y, _x.table_pose.center.orientation.z, _x.table_pose.center.orientation.w, _x.table_pose.size.x, _x.table_pose.size.y, _x.table_pose.size.z, _x.shelf_pose.center.position.x, _x.shelf_pose.center.position.y, _x.shelf_pose.center.position.z, _x.shelf_pose.center.orientation.x, _x.shelf_pose.center.orientation.y, _x.shelf_pose.center.orientation.z, _x.shelf_pose.center.orientation.w, _x.shelf_pose.size.x, _x.shelf_pose.size.y, _x.shelf_pose.size.z))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.det_2d is None:
        self.det_2d = vision_msgs.msg.Detection2DArray()
      if self.instance_id is None:
        self.instance_id = std_msgs.msg.Int16MultiArray()
      if self.det_3d is None:
        self.det_3d = vision_msgs.msg.Detection3DArray()
      if self.grasp_pose is None:
        self.grasp_pose = geometry_msgs.msg.PoseArray()
      if self.table_pose is None:
        self.table_pose = vision_msgs.msg.BoundingBox3D()
      if self.shelf_pose is None:
        self.shelf_pose = vision_msgs.msg.BoundingBox3D()
      end = 0
      _x = self
      start = end
      end += 13
      (_x.success, _x.det_2d.header.seq, _x.det_2d.header.stamp.secs, _x.det_2d.header.stamp.nsecs,) = _get_struct_B3I().unpack(str[start:end])
      self.success = bool(self.success)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.det_2d.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.det_2d.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.det_2d.detections = []
      for i in range(0, length):
        val1 = vision_msgs.msg.Detection2D()
        _v82 = val1.header
        start = end
        end += 4
        (_v82.seq,) = _get_struct_I().unpack(str[start:end])
        _v83 = _v82.stamp
        _x = _v83
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v82.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v82.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.results = []
        for i in range(0, length):
          val2 = vision_msgs.msg.ObjectHypothesisWithPose()
          _x = val2
          start = end
          end += 16
          (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
          _v84 = val2.pose
          _v85 = _v84.pose
          _v86 = _v85.position
          _x = _v86
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
          _v87 = _v85.orientation
          _x = _v87
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
          start = end
          end += 288
          _v84.covariance = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=36)
          val1.results.append(val2)
        _v88 = val1.bbox
        _v89 = _v88.center
        _x = _v89
        start = end
        end += 24
        (_x.x, _x.y, _x.theta,) = _get_struct_3d().unpack(str[start:end])
        _x = _v88
        start = end
        end += 16
        (_x.size_x, _x.size_y,) = _get_struct_2d().unpack(str[start:end])
        _v90 = val1.source_img
        _v91 = _v90.header
        start = end
        end += 4
        (_v91.seq,) = _get_struct_I().unpack(str[start:end])
        _v92 = _v91.stamp
        _x = _v92
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v91.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v91.frame_id = str[start:end]
        _x = _v90
        start = end
        end += 8
        (_x.height, _x.width,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v90.encoding = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v90.encoding = str[start:end]
        _x = _v90
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _get_struct_BI().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        _v90.data = str[start:end]
        self.det_2d.detections.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.instance_id.layout.dim = []
      for i in range(0, length):
        val1 = std_msgs.msg.MultiArrayDimension()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.label = str[start:end].decode('utf-8', 'rosmsg')
        else:
          val1.label = str[start:end]
        _x = val1
        start = end
        end += 8
        (_x.size, _x.stride,) = _get_struct_2I().unpack(str[start:end])
        self.instance_id.layout.dim.append(val1)
      start = end
      end += 4
      (self.instance_id.layout.data_offset,) = _get_struct_I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sh'%length
      start = end
      s = struct.Struct(pattern)
      end += s.size
      self.instance_id.data = numpy.frombuffer(str[start:end], dtype=numpy.int16, count=length)
      _x = self
      start = end
      end += 12
      (_x.det_3d.header.seq, _x.det_3d.header.stamp.secs, _x.det_3d.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.det_3d.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.det_3d.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.det_3d.detections = []
      for i in range(0, length):
        val1 = vision_msgs.msg.Detection3D()
        _v93 = val1.header
        start = end
        end += 4
        (_v93.seq,) = _get_struct_I().unpack(str[start:end])
        _v94 = _v93.stamp
        _x = _v94
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v93.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v93.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.results = []
        for i in range(0, length):
          val2 = vision_msgs.msg.ObjectHypothesisWithPose()
          _x = val2
          start = end
          end += 16
          (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
          _v95 = val2.pose
          _v96 = _v95.pose
          _v97 = _v96.position
          _x = _v97
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
          _v98 = _v96.orientation
          _x = _v98
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
          start = end
          end += 288
          _v95.covariance = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=36)
          val1.results.append(val2)
        _v99 = val1.bbox
        _v100 = _v99.center
        _v101 = _v100.position
        _x = _v101
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v102 = _v100.orientation
        _x = _v102
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        _v103 = _v99.size
        _x = _v103
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v104 = val1.source_cloud
        _v105 = _v104.header
        start = end
        end += 4
        (_v105.seq,) = _get_struct_I().unpack(str[start:end])
        _v106 = _v105.stamp
        _x = _v106
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v105.frame_id = str[start:end].decode('utf-8', 'rosmsg')
        else:
          _v105.frame_id = str[start:end]
        _x = _v104
        start = end
        end += 8
        (_x.height, _x.width,) = _get_struct_2I().unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v104.fields = []
        for i in range(0, length):
          val3 = sensor_msgs.msg.PointField()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val3.name = str[start:end].decode('utf-8', 'rosmsg')
          else:
            val3.name = str[start:end]
          _x = val3
          start = end
          end += 9
          (_x.offset, _x.datatype, _x.count,) = _get_struct_IBI().unpack(str[start:end])
          _v104.fields.append(val3)
        _x = _v104
        start = end
        end += 9
        (_x.is_bigendian, _x.point_step, _x.row_step,) = _get_struct_B2I().unpack(str[start:end])
        _v104.is_bigendian = bool(_v104.is_bigendian)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        _v104.data = str[start:end]
        start = end
        end += 1
        (_v104.is_dense,) = _get_struct_B().unpack(str[start:end])
        _v104.is_dense = bool(_v104.is_dense)
        self.det_3d.detections.append(val1)
      _x = self
      start = end
      end += 12
      (_x.grasp_pose.header.seq, _x.grasp_pose.header.stamp.secs, _x.grasp_pose.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.grasp_pose.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.grasp_pose.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.grasp_pose.poses = []
      for i in range(0, length):
        val1 = geometry_msgs.msg.Pose()
        _v107 = val1.position
        _x = _v107
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v108 = val1.orientation
        _x = _v108
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        self.grasp_pose.poses.append(val1)
      _x = self
      start = end
      end += 160
      (_x.table_pose.center.position.x, _x.table_pose.center.position.y, _x.table_pose.center.position.z, _x.table_pose.center.orientation.x, _x.table_pose.center.orientation.y, _x.table_pose.center.orientation.z, _x.table_pose.center.orientation.w, _x.table_pose.size.x, _x.table_pose.size.y, _x.table_pose.size.z, _x.shelf_pose.center.position.x, _x.shelf_pose.center.position.y, _x.shelf_pose.center.position.z, _x.shelf_pose.center.orientation.x, _x.shelf_pose.center.orientation.y, _x.shelf_pose.center.orientation.z, _x.shelf_pose.center.orientation.w, _x.shelf_pose.size.x, _x.shelf_pose.size.y, _x.shelf_pose.size.z,) = _get_struct_20d().unpack(str[start:end])
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_20d = None
def _get_struct_20d():
    global _struct_20d
    if _struct_20d is None:
        _struct_20d = struct.Struct("<20d")
    return _struct_20d
_struct_2I = None
def _get_struct_2I():
    global _struct_2I
    if _struct_2I is None:
        _struct_2I = struct.Struct("<2I")
    return _struct_2I
_struct_2d = None
def _get_struct_2d():
    global _struct_2d
    if _struct_2d is None:
        _struct_2d = struct.Struct("<2d")
    return _struct_2d
_struct_36d = None
def _get_struct_36d():
    global _struct_36d
    if _struct_36d is None:
        _struct_36d = struct.Struct("<36d")
    return _struct_36d
_struct_3I = None
def _get_struct_3I():
    global _struct_3I
    if _struct_3I is None:
        _struct_3I = struct.Struct("<3I")
    return _struct_3I
_struct_3d = None
def _get_struct_3d():
    global _struct_3d
    if _struct_3d is None:
        _struct_3d = struct.Struct("<3d")
    return _struct_3d
_struct_4d = None
def _get_struct_4d():
    global _struct_4d
    if _struct_4d is None:
        _struct_4d = struct.Struct("<4d")
    return _struct_4d
_struct_B = None
def _get_struct_B():
    global _struct_B
    if _struct_B is None:
        _struct_B = struct.Struct("<B")
    return _struct_B
_struct_B2I = None
def _get_struct_B2I():
    global _struct_B2I
    if _struct_B2I is None:
        _struct_B2I = struct.Struct("<B2I")
    return _struct_B2I
_struct_B3I = None
def _get_struct_B3I():
    global _struct_B3I
    if _struct_B3I is None:
        _struct_B3I = struct.Struct("<B3I")
    return _struct_B3I
_struct_BI = None
def _get_struct_BI():
    global _struct_BI
    if _struct_BI is None:
        _struct_BI = struct.Struct("<BI")
    return _struct_BI
_struct_IBI = None
def _get_struct_IBI():
    global _struct_IBI
    if _struct_IBI is None:
        _struct_IBI = struct.Struct("<IBI")
    return _struct_IBI
_struct_qd = None
def _get_struct_qd():
    global _struct_qd
    if _struct_qd is None:
        _struct_qd = struct.Struct("<qd")
    return _struct_qd
class perception(object):
  _type          = 'symbolic_msgs/perception'
  _md5sum = '66a96c4350836d51ca0d6a2c28ae7f73'
  _request_class  = perceptionRequest
  _response_class = perceptionResponse
